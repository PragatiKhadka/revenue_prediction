# Packages / libraries
import os
import numpy as np 
import pandas as pd
from matplotlib import pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, explained_variance_score, mean_absolute_error, mean_squared_error
from math import sqrt
import json
import datetime as dt

# To change scientific numbers to float
np.set_printoptions(formatter={'float_kind':'{:f}'.format})

# Increases the size of sns plots
sns.set(rc={'figure.figsize':(5,5)})

# view all the dataframe
pd.set_option('display.max_columns', None)
#pd.set_option('display.max_rows', None)

# remove warnings
import warnings
warnings.filterwarnings("ignore")

with open(r"/Users/Jorg/Accounton data/accounton_data.json",'r') as f:
    raw_data = json.loads(f.read())

# Flatten data
data = pd.json_normalize(raw_data)

# convert the CreationDate column into DateTime type Delet the companies the created after 2019 because it had many NaN values
data['creation_date'] = pd.to_datetime(data['creation_date']).dt.to_period('Y')

# Save the rows tha have values .. deleting the rows that have all NAN values
df1 = data[data['ebit.2019'].notna()]

# Split the Nace_code to git the first 2 digits
df1['Nace_code'] = df1['nace_code'].str[0:2]

df1 = df1.drop(columns=['company_name', 'zipcode', 'city', 'creation_date', 'legal_form'])

company_cat = ['Large', 'Medium sized','Small','Very large']
province =  ['Antwerp','East-Flanders','Limburg','Vlaams Brabant','West-Flanders']
nace_code_list = list(df1['Nace_code'])

years = ['2015', '2016','2017', '2018','2019','2020']
Features = ['ebit', 'ebitda' , 'profit_and_loss_after_taxes' , 'total_assets' , 'total_liabilities' ,
    'operating_profit_and_loss' , 'financial_profit_and_loss' ,
    'staff_count' , 'net_added_value' , 'staff_costs','revenue']
 
# fill the NAN values in each feature based on the median values of the same category in same provine and activites

df_after_drop = df1.dropna(subset=['revenue.2020', 'revenue.2019',
       'revenue.2018', 'revenue.2017', 'revenue.2016', 'revenue.2015'])
print(df_after_drop.shape)

for each_category in company_cat:
    for each_province in province:
        median_df =df1.groupby(['company_category', 'province', 'Nace_code']).median()
        i = median_df.loc[each_category, each_province]
        nace_list = i.index
        nace_list = list(nace_list)

        for nc in nace_list:
                    for feature in Features:
                        for year in years:
                            median = median_df.loc[(each_category, each_province, nc),f'{feature}.{year}']
                            df1[f'{feature}.{year}'].fillna(median, inplace=True)
                            if feature == 'staff_costs':
                                df1.loc[df1[f'{feature}.{year}']==0.0,f'{feature}.{year}']=median

# making the reshape 
# create a dataframe to save and arrange the data 
reshape_df = pd.DataFrame()
# creat the final complete data frame
full_df = pd.DataFrame()
# determine the years and the features
years = ['2015', '2016','2017', '2018','2019']
Features = ['ebit', 'ebitda' , 'profit_and_loss_after_taxes' , 'total_assets' , 'total_liabilities' ,
    'operating_profit_and_loss' , 'financial_profit_and_loss' ,
    'staff_count' , 'net_added_value' , 'staff_costs']
# Loop to access the data from the original dataframe and assigh it in the new dataframe
for y in years:
                
                # reshape_df['vat_number'] = df1['vat_number']
                reshape_df['vat_number']= df1['vat_number']
                reshape_df['company_category'] = df1['company_category']
                reshape_df['province'] = df1['province']
                reshape_df['nace_code'] = df1['nace_code']
                reshape_df['Nace_code'] = df1['Nace_code']
                reshape_df['Year'] = y
                
                for f in Features:
                    reshape_df[f"{f}"] = df1[f"{f}.{y}"]
                reshape_df[f"current_revenue"] = df1[f"revenue.{y}"]
                reshape_df[f"next_year_revenue"] = df1[f"revenue.{str(int(y)+1)}"]
                full_df = pd.concat([full_df,reshape_df], axis=0)

#full_df.isna().sum()

full_df = full_df.sort_values(['vat_number','Year'])

full_df = full_df[['company_category', 'province', 'ebit', 'total_liabilities', 'net_added_value', 'staff_costs', 'current_revenue', 'next_year_revenue']]

# Converting the categorical data of (Company_category and province) into numerical 
df_category = pd.get_dummies(full_df['company_category'])
df_new = pd.concat([full_df, df_category], axis=1)

df_province = pd.get_dummies(full_df['province'])
df_new = pd.concat([df_new, df_province], axis=1)
df_new

# .corr() is used to find the pairwise correlation of all columns in the dataframe. Any null values are automatically excluded
corr = full_df.corr()

# select the features and create the final dataset
training_df= df_new.drop(columns=['province'])

training_df.to_csv('/Users/Jorg/Accounton data/clean_accounton.csv', index=False)

