{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a1c6b94",
   "metadata": {},
   "source": [
    "#### Revenue Prediction Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aeb6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To change scientific numbers to float\n",
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "\n",
    "# view all the dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# remove warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b80a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "with open(r\"accounton_data.json\",'r') as f:\n",
    "    raw_data = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c43d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten json data\n",
    "data = pd.json_normalize(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044278c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the CreationDate column into DateTime\n",
    "data['creation_date'] = pd.to_datetime(data['creation_date']).dt.to_period('Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52566234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deselect data which has many null values\n",
    "df1 = data[data['ebit.2019'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fccf8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Nace_code to get the first 2 digits\n",
    "df1['Nace_code'] = df1['nace_code'].str[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9ddd59",
   "metadata": {},
   "source": [
    "#### Reshape the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9563771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe to save and arrange the data \n",
    "reshape_df = pd.DataFrame()\n",
    "# create the final complete data frame\n",
    "full_df = pd.DataFrame()\n",
    "# determine the years and the features\n",
    "years = ['2015', '2016','2017', '2018','2019']\n",
    "Features = ['ebit', 'ebitda' , 'profit_and_loss_after_taxes' , 'total_assets' , 'total_liabilities' ,\n",
    "            'operating_profit_and_loss' , 'financial_profit_and_loss' ,\n",
    "            'staff_count' , 'net_added_value' , 'staff_costs']\n",
    "\n",
    "# Loop to access the data from the original dataframe and assign it in the new dataframe\n",
    "for y in years:\n",
    "    reshape_df['vat_number']= df1['vat_number']\n",
    "    reshape_df['company_category'] = df1['company_category']\n",
    "    reshape_df['province'] = df1['province']\n",
    "    reshape_df['nace_code'] = df1['nace_code']\n",
    "    reshape_df['Nace_code'] = df1['Nace_code']\n",
    "    reshape_df['Year'] = y\n",
    "    reshape_df[f\"current_revenue\"] = df1[f\"revenue.{y}\"]\n",
    "    \n",
    "    for f in Features:\n",
    "        reshape_df[f\"{f}\"] = df1[f\"{f}.{y}\"]\n",
    "    \n",
    "    # add the next year revenue column based on the current revenue\n",
    "    reshape_df[f\"next_year_revenue\"] = df1[f\"revenue.{str(int(y)+1)}\"]\n",
    "    \n",
    "    # join the dataframe to create full dataframe\n",
    "    full_df = pd.concat([full_df,reshape_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5476efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the rows where there is no current revenue value\n",
    "full_df_after_drop = full_df.dropna(subset=['current_revenue'])\n",
    "\n",
    "# Remove the rows where there next_year_revenue column is null\n",
    "full_df_after_drop = full_df_after_drop.dropna(subset=['next_year_revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860a6515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The correction matrix to find the correlation between the features\n",
    "corr_matrix = full_df_after_drop.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092b2adf",
   "metadata": {},
   "source": [
    "#### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed1ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(x=full_df_after_drop['ebit'], y=full_df_after_drop['next_year_revenue'])\n",
    "plt.scatter(full_df_after_drop['ebitda'], full_df_after_drop['next_year_revenue'], color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c0e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(full_df_after_drop['profit_and_loss_after_taxes'], full_df_after_drop['next_year_revenue'],)\n",
    "plt.scatter(full_df_after_drop['operating_profit_and_loss'], full_df_after_drop['next_year_revenue'], color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35b7160",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(full_df_after_drop['staff_count'], full_df_after_drop['next_year_revenue'])\n",
    "plt.scatter(full_df_after_drop['staff_costs'], full_df_after_drop['next_year_revenue'], color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "print('corr', full_df_after_drop['staff_count']. corr(full_df_after_drop['staff_costs']))\n",
    "plt.scatter(full_df_after_drop['staff_count'], full_df_after_drop['staff_costs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3366bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(full_df_after_drop['financial_profit_and_loss'], full_df_after_drop['next_year_revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb29d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "print('corr', full_df_after_drop['total_liabilities']. corr(full_df_after_drop['total_assets']))\n",
    "plt.scatter(full_df_after_drop['total_assets'], full_df_after_drop['next_year_revenue'])\n",
    "plt.scatter(full_df_after_drop['total_liabilities'], full_df_after_drop['next_year_revenue'], color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d87d70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.scatter(full_df_after_drop['net_added_value'], full_df_after_drop['next_year_revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e14cb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(full_df_after_drop['current_revenue'], full_df_after_drop['next_year_revenue'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1099c684",
   "metadata": {},
   "source": [
    "According to the values of the correlation matrix and the data values we choose `ebit`, `total_liabilities`, `net_added_value`, `staff_costs`, `current_revenue` numerical columns as numerical features. And `company_category` and `Province` as categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68614b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selected Numerical features to fill in the null values\n",
    "Features = ['ebit', 'total_liabilities' , 'net_added_value' , 'staff_costs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18247f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_cat = full_df_after_drop['company_category'].unique()\n",
    "province = full_df_after_drop['province'].unique()\n",
    "years = full_df_after_drop['Year'].unique()\n",
    "nace_code_list = list(full_df_after_drop['Nace_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0303ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the NAN values in each feature based on the median values of the same company_category/province/nace_code\n",
    "median_df =full_df_after_drop.groupby(['company_category', 'province', 'Nace_code']).median()\n",
    "for each_category in company_cat:\n",
    "    for each_province in province:\n",
    "        i = median_df.loc[each_category, each_province]\n",
    "        nace_list = i.index\n",
    "        nace_list = list(nace_list)\n",
    "        for nc in nace_list:\n",
    "            for feature in Features:\n",
    "                median = median_df.loc[(each_category, each_province, nc),f'{feature}']\n",
    "                full_df_after_drop[f'{feature}'].fillna(median, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80efc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the staff_cost(if 0) with the median of the staff_cost if staff_count is null \n",
    "\n",
    "median_df =full_df_after_drop.groupby(['company_category', 'province', 'Nace_code']).median()\n",
    "\n",
    "for each_category in company_cat:\n",
    "    for each_province in province:\n",
    "        i = median_df.loc[each_category, each_province]\n",
    "        nace_list = i.index\n",
    "        nace_list = list(nace_list)\n",
    "        for nc in nace_list:\n",
    "            median = median_df.loc[(each_category, each_province, nc), 'staff_costs']\n",
    "            full_df_after_drop.loc[(full_df_after_drop['company_category'] == each_category) &\n",
    "                                   (full_df_after_drop['province'] == each_province) &\n",
    "                                   (full_df_after_drop['Nace_code'] == nc) &\n",
    "                                   (full_df_after_drop['staff_count'].isna()) & \n",
    "                                   (full_df_after_drop['staff_costs']==0.0), 'staff_costs'] = median\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca948d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the full features (categorical and numerical)\n",
    "full_df_after_drop = full_df_after_drop[['company_category', 'province', 'ebit', 'total_liabilities', \n",
    "                                         'net_added_value', 'staff_costs', 'current_revenue', 'next_year_revenue']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca1dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the categorical data of (Company_category and province) into numerical \n",
    "df_category = pd.get_dummies(full_df_after_drop['company_category'])\n",
    "df_cat = pd.concat([full_df_after_drop, df_category], axis=1)\n",
    "df_province = pd.get_dummies(full_df_after_drop['province'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd9a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the dataframe  to make the complete dataframe\n",
    "df_training = pd.concat([df_cat, df_province], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e8823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the unnecessary columns\n",
    "df_training= df_training.drop(columns=['company_category', 'province'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e61d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataset to csv\n",
    "df_training.to_csv('clean_accounton.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_ml",
   "language": "python",
   "name": "env_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
